{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jAjK2oatpFLG"
   },
   "source": [
    "<table><tr><td><img src=\"data:image/png;base64,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\" alt=\"\" /></table></tr></td>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TbFazecAFQKJ"
   },
   "source": [
    "#Week01 - Assignment01: Retinal Disease Classification (Tensorflow Vesrion)\n",
    "<hr>\n",
    "\n",
    "###@Class: Advanced Computer Vision\n",
    "###@Organize: VietAI\n",
    "###@Description: We are proceeding to build a CNN model that allows to diagnosis  retinal diseases.\n",
    "\n",
    "<b>Student Infomation:</b>\n",
    "- Name: [your fullname]\n",
    "- Email: [your email]\n",
    "- Phone: [your phone]\n",
    "\n",
    "<b>Describe your methods:</b>\n",
    "\n",
    "Describes your method here....\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U_RFsb_cacFY"
   },
   "source": [
    "#Step 01: Setup Environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QyA6LEduasVA"
   },
   "source": [
    "##Check Colab GPU Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1146,
     "status": "ok",
     "timestamp": 1599402581387,
     "user": {
      "displayName": "Tan-Cong Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiV92CXeghnsgOifVaxLYz2B0Ym-8Mngvm1IsvE=s64",
      "userId": "08664092009616942097"
     },
     "user_tz": -420
    },
    "id": "Q4brLgYDbFoa",
    "outputId": "d27032af-0d4f-4307-a069-6ec6068cc4dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep  6 14:29:41 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   38C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X1roan-jcPYo"
   },
   "source": [
    "##Connect to Google Drive\n",
    "You may be need store your own data later. Let Connect to Goole Drive for saving some necessary data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40255,
     "status": "ok",
     "timestamp": 1599402624900,
     "user": {
      "displayName": "Tan-Cong Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiV92CXeghnsgOifVaxLYz2B0Ym-8Mngvm1IsvE=s64",
      "userId": "08664092009616942097"
     },
     "user_tz": -420
    },
    "id": "fNruKWU0GFKF",
    "outputId": "4fe3e9f9-0f46-48a7-ab0e-c2e5e8f91c38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4tqRG_2-er5M"
   },
   "source": [
    "##Import and install all neccessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5392,
     "status": "ok",
     "timestamp": 1599403159427,
     "user": {
      "displayName": "Tan-Cong Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiV92CXeghnsgOifVaxLYz2B0Ym-8Mngvm1IsvE=s64",
      "userId": "08664092009616942097"
     },
     "user_tz": -420
    },
    "id": "NUs6p2SXfU3s",
    "outputId": "b6ebb14f-0763-42f4-93b8-4ba9c21833fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Authentication and download file from Google Drive\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import zipfile\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from fastprogress import master_bar, progress_bar\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Enable Eager Execution\n",
    "#tf.enable_eager_execution() # No need use this, already enable with tf version >=2.0\n",
    "tf.executing_eagerly() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DJbtAIeHeCrT"
   },
   "source": [
    "#Step 02: Reparing Retinal Disease Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d7Oqc6Pbfnv3"
   },
   "source": [
    "##Download retinal disease dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28013,
     "status": "ok",
     "timestamp": 1599403590422,
     "user": {
      "displayName": "Tan-Cong Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiV92CXeghnsgOifVaxLYz2B0Ym-8Mngvm1IsvE=s64",
      "userId": "08664092009616942097"
     },
     "user_tz": -420
    },
    "id": "xVZ1LcKlfmkd",
    "outputId": "38087dfc-fda6-4876-962a-7d09ff1895dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vietai_advance_w1b_retinal_disease_classificaton.zip ...\n",
      "Uncompressing vietai_advance_w1b_retinal_disease_classificaton.zip ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv', 'test', 'train', 'train.csv', 'baseline_model']"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Restore all data from Google Drive to virtual Colab machine with File ID\n",
    "zip_id = '1Nl4rhnP_22dJc_mbWvc4mv3e9Kmsv5JU' \n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "print (\"Downloading vietai_advance_w1b_retinal_disease_classificaton.zip ...\")\n",
    "myzip = drive.CreateFile({'id': zip_id})\n",
    "myzip.GetContentFile('vietai_advance_w1b_retinal_disease_classificaton.zip')\n",
    "\n",
    "print (\"Uncompressing vietai_advance_w1b_retinal_disease_classificaton.zip ...\")\n",
    "if not os.path.exists('retina_dataset'):\n",
    "    os.makedirs('retina_dataset')\n",
    "zip_ref = zipfile.ZipFile('vietai_advance_w1b_retinal_disease_classificaton.zip', 'r')\n",
    "zip_ref.extractall('retina_dataset')\n",
    "zip_ref.close()\n",
    "os.remove(\"vietai_advance_w1b_retinal_disease_classificaton.zip\")\n",
    "\n",
    "os.listdir(\"retina_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uxpNzGEJLmuB"
   },
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1042,
     "status": "ok",
     "timestamp": 1599402688548,
     "user": {
      "displayName": "Tan-Cong Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiV92CXeghnsgOifVaxLYz2B0Ym-8Mngvm1IsvE=s64",
      "userId": "08664092009616942097"
     },
     "user_tz": -420
    },
    "id": "876Pm72jLmuC",
    "outputId": "4c4ad324-eabf-4b30-8535-4daed2680f80"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opacity</th>\n",
       "      <th>diabetic retinopathy</th>\n",
       "      <th>glaucoma</th>\n",
       "      <th>macular edema</th>\n",
       "      <th>macular degeneration</th>\n",
       "      <th>retinal vascular occlusion</th>\n",
       "      <th>normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c24a1b14d253.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9ee905a41651.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3f58d128caf6.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4ce6599e7b20.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0def470360e4.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename  opacity  ...  retinal vascular occlusion  normal\n",
       "0  c24a1b14d253.jpg        0  ...                           1       0\n",
       "1  9ee905a41651.jpg        0  ...                           1       0\n",
       "2  3f58d128caf6.jpg        0  ...                           0       0\n",
       "3  4ce6599e7b20.jpg        1  ...                           0       0\n",
       "4  0def470360e4.jpg        1  ...                           0       0\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"retina_dataset/train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gRWSKx8OLmuE"
   },
   "source": [
    "## Data analyzing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNHyXU-iLmuF"
   },
   "source": [
    "###Analyze distribution of 0 and 1 for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1104,
     "status": "ok",
     "timestamp": 1598442948988,
     "user": {
      "displayName": "Tan-Cong Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiV92CXeghnsgOifVaxLYz2B0Ym-8Mngvm1IsvE=s64",
      "userId": "08664092009616942097"
     },
     "user_tz": -420
    },
    "id": "qXKsgwNtLmuF",
    "outputId": "1fea0497-36eb-46b6-e304-6a8879e6a3b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of opacity\n",
      "0    1902\n",
      "1    1533\n",
      "Name: opacity, dtype: int64\n",
      "Distribution of diabetic retinopathy\n",
      "0    2680\n",
      "1     755\n",
      "Name: diabetic retinopathy, dtype: int64\n",
      "Distribution of glaucoma\n",
      "0    2838\n",
      "1     597\n",
      "Name: glaucoma, dtype: int64\n",
      "Distribution of macular edema\n",
      "0    2919\n",
      "1     516\n",
      "Name: macular edema, dtype: int64\n",
      "Distribution of macular degeneration\n",
      "0    2861\n",
      "1     574\n",
      "Name: macular degeneration, dtype: int64\n",
      "Distribution of retinal vascular occlusion\n",
      "0    2995\n",
      "1     440\n",
      "Name: retinal vascular occlusion, dtype: int64\n",
      "Distribution of normal\n",
      "0    2910\n",
      "1     525\n",
      "Name: normal, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for label in data.columns[1:]:\n",
    "    print(\"Distribution of\", label)\n",
    "    print(data[label].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzaqVVvZLmuI"
   },
   "source": [
    "As can be observed, the number of label 0 is much more larger than label 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KDEYCX-mLmuJ"
   },
   "source": [
    "### Analyze combination of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E6SzzxeXLmuJ"
   },
   "outputs": [],
   "source": [
    "LABELS = data.columns[1:]\n",
    "def build_label(row):\n",
    "    return \",\".join([LABELS[idx] for idx, val in enumerate(row[1:]) if val == 1])\n",
    "        \n",
    "data.apply(lambda x: build_label(x), axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1963,
     "status": "ok",
     "timestamp": 1598443434901,
     "user": {
      "displayName": "Tan-Cong Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiV92CXeghnsgOifVaxLYz2B0Ym-8Mngvm1IsvE=s64",
      "userId": "08664092009616942097"
     },
     "user_tz": -420
    },
    "id": "eCoz3oH8LmuM",
    "outputId": "77bd0c1b-5406-4cd6-8f43-7cf0e87b3d1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['opacity', 'diabetic retinopathy', 'glaucoma', 'macular edema',\n",
       "       'macular degeneration', 'retinal vascular occlusion', 'normal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zIo2x7qkLmuP"
   },
   "source": [
    "As we can see, **opacity**, **normal** and **glaucoma** are diseases that share largest proportions in label distribution. The other diseases or combinations just account for small pieces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pVCn3Li3LmuQ"
   },
   "source": [
    "## Observations on the dataset\n",
    "The dataset provided is extremely imbalanced. In this baseline model, by simply train the model the original dataset, we will easily get overfitting on the training set and the score on the test set is very low. With the proposed methods below, you will tweak the training process and improve the metric score on the test set:\n",
    "- **Image Augmentation**: By augmenting images, we will have more data and make the training set become more regularize. [imgaug](https://github.com/aleju/imgaug) is a very strong augmentation library that you can use in this assignment\n",
    "- **Data sampling**: the idea here is to make the distribution between classes in the dataset balance. There are 2 kinds: oversampling and undersampling\n",
    "- **Adjust loss function**: the current loss function becomes very small after several epochs. By adding weights, we adjust the loss function to make it suitable for this imbalanced dataset. You can check the [BCEWithLogitsLoss](https://pytorch.org/docs/stable/nn.html#bcewithlogitsloss) and try applying it.\n",
    "- **To simplify the baseline model, the dataset is splited randomly. However, to improve the model, cross-validation techniques can be applied here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tzG2CGPNLmuQ"
   },
   "source": [
    "## Split the dataset\n",
    "*For* the data provided, we will split the dataset to 80% for training and 20% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gNpteQFLmuS"
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xQ5-T4AULmuU"
   },
   "source": [
    "#Step 03: Build Baseline Model\n",
    "In this notebook, we will use Pytorch library to implement and train ResNet50 as a baseline model. With initial weights from ImageNet, we will retrain all layers for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QN3mRy1uvNAc"
   },
   "source": [
    "## Set some neccessary hyperparamaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HAUZTBnTLmuV"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224                              # Image size (224x224)\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]         # Mean of ImageNet dataset (used for normalization)\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]          # Std of ImageNet dataset (used for normalization)\n",
    "BATCH_SIZE = 64                             \n",
    "LEARNING_RATE = 0.001\n",
    "LEARNING_RATE_SCHEDULE_FACTOR = 0.1           # Parameter used for reducing learning rate\n",
    "LEARNING_RATE_SCHEDULE_PATIENCE = 5           # Parameter used for reducing learning rate\n",
    "MAX_EPOCHS = 100                              # Maximum number of training epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FCM4Zm7dLmuX"
   },
   "source": [
    "## Implement Dataset loader\n",
    "In Keras, you can use `ImageDataGenerator` to feed image to the model. However, the supported augmentation of `ImageDataGenerator` is not enough, we can add more from another library in this `preprocessing_image` below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3O9SG4AWLmuX"
   },
   "outputs": [],
   "source": [
    "def preprocessing_image(image):\n",
    "    \"\"\"\n",
    "    Preprocess image after resize and augment data with ImageDataGenerator\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image: numpy tensor with rank 3\n",
    "        image to preprocessing\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    numpy tensor with rank 3\n",
    "    \"\"\"\n",
    "    # TODO: augment more here\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y51egkFmLmuZ"
   },
   "source": [
    "Create data generator object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z6rMwKxoLmua"
   },
   "outputs": [],
   "source": [
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "                                                             featurewise_center=True,\n",
    "                                                             featurewise_std_normalization=True,\n",
    "                                                             preprocessing_function=preprocessing_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cm1j8rw6Lmuc"
   },
   "source": [
    "`ImageDataGenerator` only accepts list of strings as label, we need to convert the label in the dataframe following that way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1089,
     "status": "ok",
     "timestamp": 1598443456443,
     "user": {
      "displayName": "Tan-Cong Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiV92CXeghnsgOifVaxLYz2B0Ym-8Mngvm1IsvE=s64",
      "userId": "08664092009616942097"
     },
     "user_tz": -420
    },
    "id": "_DVkBLO4Lmuc",
    "outputId": "4aab6b51-ff83-41dc-c99b-370515c82dcb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def build_label_list(row):\n",
    "    return [LABELS[idx] for idx, val in enumerate(row[1:]) if val == 1]\n",
    "        \n",
    "train_data[\"label\"] = train_data.apply(lambda x: build_label_list(x), axis=1)\n",
    "val_data[\"label\"] = val_data.apply(lambda x: build_label_list(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4b9eo8i8Lmue"
   },
   "source": [
    "Create training generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1079,
     "status": "ok",
     "timestamp": 1598443508266,
     "user": {
      "displayName": "Tan-Cong Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiV92CXeghnsgOifVaxLYz2B0Ym-8Mngvm1IsvE=s64",
      "userId": "08664092009616942097"
     },
     "user_tz": -420
    },
    "id": "ftQ_jLJ9Lmuf",
    "outputId": "8c78212f-5344-4ae4-d86e-050e829220a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2748 validated image filenames belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = train_datagen.flow_from_dataframe(dataframe=train_data, \n",
    "                                        directory=\"retina_dataset/train/train\", \n",
    "                                        x_col=\"filename\", \n",
    "                                        y_col=\"label\",\n",
    "                                        class_mode=\"categorical\",\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE), \n",
    "                                        batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bojKIxytLmuh"
   },
   "source": [
    "We also need to create validation generator. Different from training generator, we don't shuffle the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1105,
     "status": "ok",
     "timestamp": 1598443523165,
     "user": {
      "displayName": "Tan-Cong Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiV92CXeghnsgOifVaxLYz2B0Ym-8Mngvm1IsvE=s64",
      "userId": "08664092009616942097"
     },
     "user_tz": -420
    },
    "id": "68aN2qykLmui",
    "outputId": "b2146008-3b4c-443c-ffaf-88fa87ada1c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 687 validated image filenames belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "val_gen = train_datagen.flow_from_dataframe(dataframe=val_data, \n",
    "                                        directory=\"retina_dataset/train/train\", \n",
    "                                        x_col=\"filename\", \n",
    "                                        y_col=\"label\",\n",
    "                                        class_mode=\"categorical\",\n",
    "                                        shuffle=False,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE), \n",
    "                                        batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8hY_VRxrLmul"
   },
   "source": [
    "## Define model\n",
    "In the baseline, we use ResNet50 pretrained on ImageNet dataset. The classifier of model would be replaced with a new dense layer to make the output suit the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11517,
     "status": "ok",
     "timestamp": 1598443539142,
     "user": {
      "displayName": "Tan-Cong Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiV92CXeghnsgOifVaxLYz2B0Ym-8Mngvm1IsvE=s64",
      "userId": "08664092009616942097"
     },
     "user_tz": -420
    },
    "id": "Wfb6uYcmLmup",
    "outputId": "309994e1-1163-4fb7-b877-265bb9bbb2cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 2s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 7)                 14343     \n",
      "=================================================================\n",
      "Total params: 23,602,055\n",
      "Trainable params: 23,548,935\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.ResNet50(input_shape=(IMAGE_SIZE,IMAGE_SIZE,3),\n",
    "                                    include_top=False,\n",
    "                                    weights='imagenet')\n",
    "base_model.trainable = True\n",
    "\n",
    "model = keras.Sequential([\n",
    "  base_model,\n",
    "  keras.layers.GlobalAveragePooling2D(),\n",
    "  keras.layers.Dense(len(LABELS), activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Print out model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BLefUQzTLmuq"
   },
   "source": [
    "We need to train about 23 millions parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_ozLFddxile"
   },
   "source": [
    "#Step 04: Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gD0QP-tYLmur"
   },
   "source": [
    "## Define F1-score\n",
    "Keras recently removed the F1-score metric, we will implement it in the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lfUp_CL5Lmur"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VnQhFJlzLmut"
   },
   "source": [
    "## Define callbacks\n",
    "There are 2 callbacks we need to add to the training:\n",
    "- Saving the best model on validation set\n",
    "- Reduce learning rate during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-EiuKMT2Lmut"
   },
   "outputs": [],
   "source": [
    "mcp = keras.callbacks.ModelCheckpoint(\"resnet50.h5\", monitor=\"val_f1\", save_best_only=True, save_weights_only=True, verbose=1,mode='max')\n",
    "rlr = keras.callbacks.ReduceLROnPlateau(monitor='val_f1', factor=LEARNING_RATE_SCHEDULE_FACTOR, mode='max', patience=LEARNING_RATE_SCHEDULE_PATIENCE, min_lr=1e-8, verbose=1)\n",
    "callbacks = [mcp, rlr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yzLlNFw-Lmuv"
   },
   "source": [
    "## Training\n",
    "Fully training model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "w2-DeQKSLmuw",
    "outputId": "742142e6-2975-4303-fdae-7962161f3ebb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-30-9b9740976a20>:16: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 2/42 [>.............................] - ETA: 12s - loss: 0.5342 - f1: 0.3254WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2375s vs `on_train_batch_end` time: 0.3792s). Check your callbacks.\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3766 - f1: 0.5263\n",
      "Epoch 00001: val_f1 improved from -inf to 0.12559, saving model to resnet50.h5\n",
      "42/42 [==============================] - 31s 744ms/step - loss: 0.3766 - f1: 0.5263 - val_loss: 1236.3823 - val_f1: 0.1256\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2833 - f1: 0.6651\n",
      "Epoch 00002: val_f1 did not improve from 0.12559\n",
      "42/42 [==============================] - 29s 685ms/step - loss: 0.2833 - f1: 0.6651 - val_loss: 71.7005 - val_f1: 0.1256\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2324 - f1: 0.7360\n",
      "Epoch 00003: val_f1 did not improve from 0.12559\n",
      "42/42 [==============================] - 29s 691ms/step - loss: 0.2324 - f1: 0.7360 - val_loss: 13.6276 - val_f1: 0.1256\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1939 - f1: 0.7886\n",
      "Epoch 00004: val_f1 improved from 0.12559 to 0.36005, saving model to resnet50.h5\n",
      "42/42 [==============================] - 30s 708ms/step - loss: 0.1939 - f1: 0.7886 - val_loss: 3.1427 - val_f1: 0.3601\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1642 - f1: 0.8293\n",
      "Epoch 00005: val_f1 improved from 0.36005 to 0.36144, saving model to resnet50.h5\n",
      "42/42 [==============================] - 30s 707ms/step - loss: 0.1642 - f1: 0.8293 - val_loss: 0.6736 - val_f1: 0.3614\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1176 - f1: 0.8854\n",
      "Epoch 00006: val_f1 did not improve from 0.36144\n",
      "42/42 [==============================] - 30s 706ms/step - loss: 0.1176 - f1: 0.8854 - val_loss: 0.9073 - val_f1: 0.3614\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0910 - f1: 0.9158\n",
      "Epoch 00007: val_f1 improved from 0.36144 to 0.37993, saving model to resnet50.h5\n",
      "42/42 [==============================] - 30s 716ms/step - loss: 0.0910 - f1: 0.9158 - val_loss: 0.8530 - val_f1: 0.3799\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0724 - f1: 0.9303\n",
      "Epoch 00008: val_f1 did not improve from 0.37993\n",
      "42/42 [==============================] - 30s 709ms/step - loss: 0.0724 - f1: 0.9303 - val_loss: 1.0811 - val_f1: 0.3799\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0523 - f1: 0.9566\n",
      "Epoch 00009: val_f1 did not improve from 0.37993\n",
      "42/42 [==============================] - 30s 708ms/step - loss: 0.0523 - f1: 0.9566 - val_loss: 0.7043 - val_f1: 0.3614\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0354 - f1: 0.9725\n",
      "Epoch 00010: val_f1 improved from 0.37993 to 0.38285, saving model to resnet50.h5\n",
      "42/42 [==============================] - 30s 719ms/step - loss: 0.0354 - f1: 0.9725 - val_loss: 0.7392 - val_f1: 0.3828\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0329 - f1: 0.9729\n",
      "Epoch 00011: val_f1 did not improve from 0.38285\n",
      "42/42 [==============================] - 30s 715ms/step - loss: 0.0329 - f1: 0.9729 - val_loss: 0.8650 - val_f1: 0.3799\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0273 - f1: 0.9781\n",
      "Epoch 00012: val_f1 did not improve from 0.38285\n",
      "42/42 [==============================] - 30s 715ms/step - loss: 0.0273 - f1: 0.9781 - val_loss: 1.0862 - val_f1: 0.3608\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0179 - f1: 0.9860\n",
      "Epoch 00013: val_f1 did not improve from 0.38285\n",
      "42/42 [==============================] - 30s 718ms/step - loss: 0.0179 - f1: 0.9860 - val_loss: 1.6084 - val_f1: 0.3808\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0156 - f1: 0.9895\n",
      "Epoch 00014: val_f1 did not improve from 0.38285\n",
      "42/42 [==============================] - 30s 714ms/step - loss: 0.0156 - f1: 0.9895 - val_loss: 1.9059 - val_f1: 0.3652\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0150 - f1: 0.9889\n",
      "Epoch 00015: val_f1 improved from 0.38285 to 0.39177, saving model to resnet50.h5\n",
      "42/42 [==============================] - 30s 726ms/step - loss: 0.0150 - f1: 0.9889 - val_loss: 2.5765 - val_f1: 0.3918\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0158 - f1: 0.9877\n",
      "Epoch 00016: val_f1 improved from 0.39177 to 0.41942, saving model to resnet50.h5\n",
      "42/42 [==============================] - 30s 725ms/step - loss: 0.0158 - f1: 0.9877 - val_loss: 0.7000 - val_f1: 0.4194\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0163 - f1: 0.9865\n",
      "Epoch 00017: val_f1 improved from 0.41942 to 0.42975, saving model to resnet50.h5\n",
      "42/42 [==============================] - 30s 723ms/step - loss: 0.0163 - f1: 0.9865 - val_loss: 1.7699 - val_f1: 0.4298\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0141 - f1: 0.9876\n",
      "Epoch 00018: val_f1 did not improve from 0.42975\n",
      "42/42 [==============================] - 30s 716ms/step - loss: 0.0141 - f1: 0.9876 - val_loss: 0.5333 - val_f1: 0.3706\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0116 - f1: 0.9909\n",
      "Epoch 00019: val_f1 improved from 0.42975 to 0.48460, saving model to resnet50.h5\n",
      "42/42 [==============================] - 30s 724ms/step - loss: 0.0116 - f1: 0.9909 - val_loss: 0.5897 - val_f1: 0.4846\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0206 - f1: 0.9829\n",
      "Epoch 00020: val_f1 did not improve from 0.48460\n",
      "42/42 [==============================] - 30s 716ms/step - loss: 0.0206 - f1: 0.9829 - val_loss: 36.5809 - val_f1: 0.1256\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0234 - f1: 0.9789\n",
      "Epoch 00021: val_f1 improved from 0.48460 to 0.49740, saving model to resnet50.h5\n",
      "42/42 [==============================] - 30s 722ms/step - loss: 0.0234 - f1: 0.9789 - val_loss: 1.1751 - val_f1: 0.4974\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0351 - f1: 0.9717\n",
      "Epoch 00022: val_f1 did not improve from 0.49740\n",
      "42/42 [==============================] - 30s 716ms/step - loss: 0.0351 - f1: 0.9717 - val_loss: 3.2813 - val_f1: 0.4594\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0210 - f1: 0.9849\n",
      "Epoch 00023: val_f1 improved from 0.49740 to 0.53129, saving model to resnet50.h5\n",
      "42/42 [==============================] - 30s 722ms/step - loss: 0.0210 - f1: 0.9849 - val_loss: 1.4024 - val_f1: 0.5313\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0153 - f1: 0.9889\n",
      "Epoch 00024: val_f1 improved from 0.53129 to 0.57434, saving model to resnet50.h5\n",
      "42/42 [==============================] - 30s 725ms/step - loss: 0.0153 - f1: 0.9889 - val_loss: 0.9127 - val_f1: 0.5743\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0107 - f1: 0.9926\n",
      "Epoch 00025: val_f1 improved from 0.57434 to 0.64198, saving model to resnet50.h5\n",
      "42/42 [==============================] - 30s 723ms/step - loss: 0.0107 - f1: 0.9926 - val_loss: 0.6529 - val_f1: 0.6420\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0061 - f1: 0.9967\n",
      "Epoch 00026: val_f1 improved from 0.64198 to 0.66005, saving model to resnet50.h5\n",
      "42/42 [==============================] - 30s 723ms/step - loss: 0.0061 - f1: 0.9967 - val_loss: 0.7435 - val_f1: 0.6601\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0028 - f1: 0.9984\n",
      "Epoch 00027: val_f1 improved from 0.66005 to 0.68944, saving model to resnet50.h5\n",
      "42/42 [==============================] - 30s 724ms/step - loss: 0.0028 - f1: 0.9984 - val_loss: 0.7159 - val_f1: 0.6894\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0014 - f1: 0.9992\n",
      "Epoch 00028: val_f1 improved from 0.68944 to 0.70662, saving model to resnet50.h5\n",
      "42/42 [==============================] - 30s 725ms/step - loss: 0.0014 - f1: 0.9992 - val_loss: 0.6218 - val_f1: 0.7066\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0011 - f1: 0.9997\n",
      "Epoch 00029: val_f1 improved from 0.70662 to 0.73089, saving model to resnet50.h5\n",
      "42/42 [==============================] - 30s 723ms/step - loss: 0.0011 - f1: 0.9997 - val_loss: 0.5273 - val_f1: 0.7309\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.1213e-04 - f1: 1.0000\n",
      "Epoch 00030: val_f1 improved from 0.73089 to 0.76700, saving model to resnet50.h5\n",
      "42/42 [==============================] - 31s 726ms/step - loss: 2.1213e-04 - f1: 1.0000 - val_loss: 0.4665 - val_f1: 0.7670\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3478e-04 - f1: 1.0000\n",
      "Epoch 00031: val_f1 improved from 0.76700 to 0.77364, saving model to resnet50.h5\n",
      "42/42 [==============================] - 30s 724ms/step - loss: 1.3478e-04 - f1: 1.0000 - val_loss: 0.4740 - val_f1: 0.7736\n",
      "Epoch 32/100\n",
      "24/42 [================>.............] - ETA: 11s - loss: 1.1330e-04 - f1: 1.0000"
     ]
    }
   ],
   "source": [
    "device = '/gpu:0'\n",
    "\n",
    "with tf.device(device):\n",
    "    steps_per_epoch = train_gen.n // BATCH_SIZE\n",
    "    validation_steps = val_gen.n // BATCH_SIZE\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=LEARNING_RATE), loss='binary_crossentropy', metrics=[f1])\n",
    "\n",
    "    # Huấn luyện\n",
    "    history = model.fit_generator(train_gen,\n",
    "                                  steps_per_epoch=steps_per_epoch,\n",
    "                                  epochs=MAX_EPOCHS,\n",
    "                                  verbose=1,\n",
    "                                  validation_data=val_gen,\n",
    "                                  validation_steps=validation_steps,\n",
    "                                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8xVcc8r_Lmux"
   },
   "source": [
    "#Step 05: Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PLK-IlbOLmuy"
   },
   "source": [
    "##Read the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "D7FXlZ3TLmuy",
    "outputId": "6257b0b1-b4a1-404a-95a0-870df8d913c8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e742d34a26d4.jpg</td>\n",
       "      <td>0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b193b6a6d68d.jpg</td>\n",
       "      <td>0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07e4191fa3a8.jpg</td>\n",
       "      <td>0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b1a911cb2e6c.jpg</td>\n",
       "      <td>0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d8ab9cda1b33.jpg</td>\n",
       "      <td>0 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename predicted\n",
       "0  e742d34a26d4.jpg       0 0\n",
       "1  b193b6a6d68d.jpg       0 0\n",
       "2  07e4191fa3a8.jpg       0 0\n",
       "3  b1a911cb2e6c.jpg       0 0\n",
       "4  d8ab9cda1b33.jpg       0 0"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"retina_dataset/sample_submission.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p0rH97YnLmu2"
   },
   "source": [
    "## Create test data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lhU2qJiwLmu2",
    "outputId": "0b2c0919-6ee5-4e8b-e19f-616f5bba6b41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 350 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_gen = train_datagen.flow_from_dataframe(dataframe=test_df,\n",
    "                                             directory=\"../input/test/test\",\n",
    "                                             x_col=\"filename\",\n",
    "                                             class_mode=None,\n",
    "                                             shuffle=False,\n",
    "                                             target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                             batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3lX7BhDTLmu5"
   },
   "source": [
    "## Load best model weights and switch to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kYIaB_RfLmu7"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"resnet50.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EsXWvg6CLmu9"
   },
   "source": [
    "##Predict test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "eNmzSZlYLmu-",
    "outputId": "9fd2b60b-2afd-40f8-adf0-233b3461414e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_generator(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1rcbNsWParw"
   },
   "outputs": [],
   "source": [
    "labels = (train_gen.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "labels\n",
    "LABELS = list(LABELS)\n",
    "\n",
    "def probs2label(probs):\n",
    "    ''' Return real index following LABELS\n",
    "    '''\n",
    "    global LABELS, labels\n",
    "    return \" \".join([str(LABELS.index(labels[idx])) for idx, prob in enumerate(probs) if prob > 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DC6tET2uRuDk"
   },
   "outputs": [],
   "source": [
    "#test_df['predicted'] = np.apply_along_axis(probs2label, 1, pred)\n",
    "for idx, row in test_df.iterrows():\n",
    "    test_df.loc[idx]['predicted'] = probs2label(pred[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hONHxoruLmvA"
   },
   "source": [
    "##Write result to submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wSFhXc-aLmvB"
   },
   "outputs": [],
   "source": [
    "test_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "rrYlWj2pYR2x",
    "outputId": "63bccea4-3562-479d-d8ac-bbc9788b4d8b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e742d34a26d4.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b193b6a6d68d.jpg</td>\n",
       "      <td>4 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07e4191fa3a8.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b1a911cb2e6c.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d8ab9cda1b33.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename predicted\n",
       "0  e742d34a26d4.jpg         6\n",
       "1  b193b6a6d68d.jpg       4 0\n",
       "2  07e4191fa3a8.jpg         0\n",
       "3  b1a911cb2e6c.jpg         0\n",
       "4  d8ab9cda1b33.jpg         2"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "teBDZAQmbJi3",
    "outputId": "8d72a912-abca-4f11-ac10-68a7c8319c18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [1.7672777e-05, 2.8789043e-04, 9.9997354e-01, ..., 0.0000000e+00,\n",
       "        9.9999058e-01, 1.2516975e-06],\n",
       "       [4.6352148e-03, 3.6647916e-04, 3.2086360e-01, ..., 6.2286854e-06,\n",
       "        9.9990308e-01, 1.9803643e-04],\n",
       "       ...,\n",
       "       [9.3174160e-01, 2.3356080e-04, 2.9428422e-02, ..., 9.3579292e-06,\n",
       "        2.3050255e-01, 4.4465065e-05],\n",
       "       [2.0586443e-01, 8.3863735e-05, 1.2040138e-05, ..., 1.8656254e-05,\n",
       "        9.9385738e-01, 2.7793646e-04],\n",
       "       [3.5405159e-05, 9.9999946e-01, 7.8678131e-06, ..., 5.9604645e-07,\n",
       "        1.3281384e-07, 6.9934458e-06]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "KCi27itudALK",
    "outputId": "f078ceb8-a679-4e60-c8a9-d981cd10d4c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diabetic retinopathy': 0,\n",
       " 'glaucoma': 1,\n",
       " 'macular degeneration': 2,\n",
       " 'macular edema': 3,\n",
       " 'normal': 4,\n",
       " 'opacity': 5,\n",
       " 'retinal vascular occlusion': 6}"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen.class_indices"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "U_RFsb_cacFY",
    "QyA6LEduasVA",
    "X1roan-jcPYo",
    "4tqRG_2-er5M",
    "DJbtAIeHeCrT",
    "d7Oqc6Pbfnv3",
    "gRWSKx8OLmuE",
    "xNHyXU-iLmuF",
    "tzG2CGPNLmuQ",
    "xQ5-T4AULmuU",
    "QN3mRy1uvNAc",
    "FCM4Zm7dLmuX",
    "8hY_VRxrLmul",
    "s_ozLFddxile",
    "gD0QP-tYLmur",
    "VnQhFJlzLmut",
    "8xVcc8r_Lmux",
    "PLK-IlbOLmuy",
    "p0rH97YnLmu2",
    "3lX7BhDTLmu5",
    "EsXWvg6CLmu9",
    "hONHxoruLmvA"
   ],
   "machine_shape": "hm",
   "name": "[Week01_Assignment01_TensorFlow]_RetinalDiseaseClassification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
